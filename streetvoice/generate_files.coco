"""
Supplement track metadata with lyrics, file ID, image ID, etc. Write cover art and audio files to disk.
"""
import sqlite3
import json
import os
import re
import paths

songs = paths.songs_file.read_text() |> json.loads

with sqlite3.connect(paths.db_file) as conn:
  for song in songs:
    (data_,) = conn.execute(f"SELECT data FROM dump WHERE path LIKE '%/song/{song['id']}/%fields=lyrics%'").fetchone()
    song['lyrics'] = json.loads(data_)['lyrics'].replace(r'\r\n', '\n')

    # Get id of .mp3 file
    (data_,) = conn.execute(f"SELECT data FROM dump WHERE path LIKE '%/song/{song['id']}/hls/file/'").fetchone()
    song['file_id'] = json.loads(data_)['file'] |> re.match$(r'.*/([a-zA-Z0-9]+)[.]mp3') |> .group(1)

    # Write cover art to disk (grab the largest image we downloaded)
    sql = f"SELECT data, content_type FROM dump WHERE path LIKE '%/{song['image_id']}%' ORDER BY length(data) DESC"
    data_, content_type = conn.execute(sql).fetchone()
    extension = re.match(r'image/([a-z]+)', content_type) |> .group(1)
    image_file = paths.assets_dir / f"{song['image_id']}.{extension}"
    image_file.write_bytes(data_)
    song['image_file'] = str(image_file)

    # Create single .ts file by concatenating individual .ts files that have the same file_id
    sql = f"SELECT data FROM dump WHERE path LIKE '%/{song['file_id']}.mp3%' ORDER BY path"
    ts_file = paths.get_ts_file(song['id'])
    if ts_file.exists():
      os.remove(ts_file)
    with ts_file.open('wb') as fp:
      for (data_,) in conn.execute(sql):
        fp.write(data_)

json.dumps(songs, indent=2, ensure_ascii=False) |> paths.songs_extra_file.write_text
